%1234567890123456789012345678901234567890123456789012345678901234567890123456789
\chapter{Introduction}
% Our problem (=dynamic motor skills) is important
Performing highly dynamic motions with agility and grace has been one of the
greatest challenges for athletes, game characters, and robots.
The philosophy of Parkour, ``an art of overcoming obstacles as swiftly and
efficiently as possible using only your body, '' shows the importance of
dynamic motor skills in two aspects: dynamic motions can be both artistic 
methods of self-expression and efficient mechanisms of transportation. 
In fact, it has been a great milestone in the various research area
to develop physics-based controllers that can execute natural 
and agile motions.
For instance, dynamic motion controllers are developed 
for game characters to generate live interactive behaviors or optimal 
motions that minimize energy consumption.
In robotics, dynamic motor skills allow robots to overcome obstacles and
to move in uneven terrains, which can be often located in 
the disaster places.
To maximize capabilities of virtual characters and robots for 
further challenging motor tasks, it is inevitable to develop 
physic-based dynamic motion controllers.

% I will solve virtual and real both, to get the benefits
Virtual characters and real robots are two main subjects of motor control
problems in computer graphics and robotics.
Although they have different applications and limitations,
it is also true that control problems of both subjects have common
properties, such as non-linearity of the objective function, 
under-actuated characters, high-dimensional control parameters, 
and discontinuity due to the contacts.
Therefore, principles and algorithms developed in one domain often can be
transferred to the other domain.
For instance, many optimization algorithms for finding the best control
parameters, such as PEGASUS and CMA-ES, have been successfully applied
to the virtual characters and robots.
Further, a virtual simulation of a robot is often used as a testbed for
developing hardware compatible controllers due to the expensive cost and
time-consuming trials.
In this dissertation, I will discuss control of both virtual and real humanoids
by demonstrating the different problem formulation and solutions, and further
proposing the optimization technique for hardware that exploits the experience
in the virtual simulation.

% The first difficulty (dynamic motion) and our approach
However, developing effective and robust controllers for dynamic motor skills 
requires a lot of manual efforts and computational resources.
Dynamic motor skills are characterized by abrupt accelerations and 
decelerations of momentum,
frequent changes of contacts, and explosive usage of torques near limitations.
Due to these attributes, controllers must be able to generate efficient
and feasible torque trajectories that can be applied to a wide range of initial
conditions for robustness.
In this dissertation, I thoroughly investigate a falling motion of humanoid 
as an example of highly dynamic motions due to several reasons.
First, it is a fundamental motor skill that protects the subject from 
severe injuries and connects the previous and next actions for fluent
transitions.
In addition, it is one of the most challenging motor skills because 
it accompanies huge changes of vertical momentum within 
a very short time window.
Therefore, the development of falling controllers will make virtual 
characters and robots to execute the motion fluently
and its principles can be applied to the other highly dynamic motions
with huge momentum.

% The second difficulty (optimization) and our approach
Another difficulty arises when optimizing input parameters for controllers.
Typically, whole-body dynamic tasks typically have a cost function
that is multimodal, non-linear, non-convex, and discontinuous due to 
an under-actuated system and discrete contacts.
Further, its control parameters are likely to be in a high dimensional
space with small feasible regions that does not generate undesired behaviors.
These difficulties often requires the most robust optimization algorithm.
In computer animation, a robust black-box sampling-based method, 
Covariance Matrix Adaption Evolution Strategy (CMA-ES) [], has been frequently
applied to discontinuous control problems, such as biped locomotion [],
parkour-style stunts[], or swimming [].
In this dissertation, I focus on improving the performance of the baseline
algorithm, CMA-ES, for more difficult tasks with smaller feasible regions
by training classifiers to exclude infeasible samples.
I further extend CMA-ES for a parametrized motor skill, which is essential
for operating a robot in the unpredictable environment.

% The third difficulty (simulation bias) and our approach
Unlikely the optimization for virtual characters
a control policy search for hardware with many trials is often infeasible
because conducting hardware experiment can be expensive and time-consuming.
Moreover, an execution of a bad controller on a robot can potentially cause
disastrous damage to the robot and enormous cost to repair.
To reduce the number of trials on the hardware, a virtual simulation 
is used as a practical solution that provides a fast and safe evaluation
of the controller.
However, it suffers from \emph{simulation bias} in which
controllers developed for a virtual character do not work on hardware due
to differences in the two systems.
The \emph{simulation bias} is hard to explicitly model because it can
be caused by many reasons, such as modeling errors, sensor and actuator noises,
or command delays.
A data-driven model-based policy search, which iteratively updates the simulation
using collected hardware data, is a promising method to 
model the simulation bias.
In this dissertation, I will discuss how can we reduce the number of hardware
experiments for robots using our iterative model-based policy search that
exploits the virtual simulation as a testbed.

% Identify three categories problems.
In this dissertation, following problems are identified for developing 
controllers for highly dynamic motor skills.

\section{Falling Strategies for Humanoids}
% Introduction on the falling - Motivation, Description, Goal
Highly dynamic motions often accompany the abrupt momentum changes, which can
cause large contact forces to characters.
Therefore, how to manage falls is a fundamental motor skill to reduce damages
to humanoids and achieve fluent transitions between motor skills.
In this dissertation, I will discuss two different falling scenarios, 
for  virtual and real humanoids.
For a virtual character, I will describe a general controller that allows the character to fall from a wide range of heights and initial speed,
which are inspired by falling of traceurs.
For a real robot, a general falling strategy for handling various 
external perturbations is introduced, which is feasible to be
executed by actual hardware.
The effectiveness of the presented strategies will be validated in physics
simulation, and experimentally tested on a small-size humanoid.

\subsection{Falling and Landing Motion Control for Virtual Characters}
% Goal, Method (Strength), Verification + Image
\begin{wrapfigure}{r}{0.5\textwidth}
 \vspace{-25pt}
  \begin{center}
    \includegraphics[width=0.48\textwidth]{images/intro_landing.jpg}
  \end{center}
   \vspace{-25pt}
  \caption{A falling motion of Parkour.}
  \label{fig:intro_landing}
   \vspace{-10pt}
\end{wrapfigure}
In Chapter 3, I will show how to create an on-line controller for generating 
agile and natural falling motions of the virtual character that can land from 
various heights and velocities.
The goals of the controller are to reduce the joint stress at the impact and
get back on its feet to prepare the next action.
Inspired by falling skills of Parkour(\figref{intro_landing}), I formulate the falling problem
with three phases, \emph{airborne}, \emph{impact}, and \emph{rolling}
based on the contact states.
First, two sub-controllers are designed for the \emph{airborne} and
\emph{rolling} phases and a regression analysis is conducted to find 
an optimal landing angle that can connect two sub controllers at the
\emph{impact} phase.
I will demonstrate that the motion generated by the proposed controller
induces smaller joint stress, which is still four times lower than a rag-doll
motion at the worst cases.

\subsection{Multiple Contact Planning for Humanoids}
\begin{wrapfigure}{l}{0.5\textwidth}
 \vspace{-25pt}
  \begin{center}
    \includegraphics[width=0.48\textwidth]{images/intro_hardware.jpg}
  \end{center}
   \vspace{-25pt}
  \caption{Hardware of BioloidGP robot.}
   \vspace{-10pt}
  \label{fig:intro_hardware}
\end{wrapfigure}
% Goal, Method (Strength), Verification + Image
Chapter 4 will describe a general algorithm which plans for appropriate 
responses to a wide variety of falls, from a single step to recover a gentle nudge, to a rolling motion to break a high-speed fall.
Our multiple contact planning provides a unified framework
that can represent many existing falling techniques [,,].
Then, I will show how to efficiently optimize the multiple contact falling
strategy to the given initial state using a simplified model and dynamic 
programming.
Finally, various scenarios will be tested on simulated humanoids and the
actual hardware (\figref{intro_hardware}) to show that our algorithm plans
various falling strategies with different contact sequences.

\section{Learning of Dynamic Controller for Characters}
% Introduction on the learning - Motivation, Description, Goal
Teaching a physically simulated character a new motor skill requires 
a lot of efforts from the controller designer, from the design of the control 
mechanism to the tweaking of low-level control parameters.
To simplify the learning process, I will introduce an intuitive and 
interactive framework for developing dynamic controllers that is inspired by
how humans learn dynamic motor skills through a iterative process of coaching
and practicing.
Further, we propose two optimization techniques that can extend the popular
policy search algorithm, CMA-ES, to accelerate the convergence rate
and to optimize a parametrized objective function.

\subsection{Iterative Design of Dynamic Controllers}
% Goal, Method (Strength), Verification + Image
\begin{wrapfigure}{r}{0.6\textwidth}
 \vspace{-10pt}
  \begin{center}
    \includegraphics[width=0.58\textwidth]{images/intro_teach.png}
  \end{center}
   \vspace{-25pt}
  \caption{The proposed learning frame uses human readable instructions
    to teach motions.}
  \label{fig:intro_teach}
   \vspace{-10pt}
\end{wrapfigure}
In Chapter 5, I will describe an iterative framework to design dynamic
controllers using high-level, human-readable instructions,
inspired by a training process of athletes that consists of
interactive coaching and repetitive practices (\figref{intro_teach})
To enable interactive coaching, I introduce ``control rigs'' as
an intermediate layer of control module to facilitate the mapping between
human instructions and low-level control parameters.
During the practicing stage, control parameters are efficiently determined
using CMA-ES, which will be further improved in the following chapters.
The details of controllers development process using our iterative learning
framework will be shown with example parkour motions.

\subsection{Optimization with Failure Learning}
% Goal, Method (Strength), Verification + Image
A controller with many user constraints is difficult to optimize due to the
relatively small feasible region.
In Chapter 6, I will describe a new optimization algorithm based on the
observation of humanâ€™s ability to learn from failure.
The proposed algorithm, CMA-C (Covariance Matrix Adaptation with
Classification) utilizes the failed simulation trials to approximate 
an infeasible region in the space of control rig parameters, resulting a
faster convergence than the standard CMA-ES.

\subsection{Optimization for Parametrized Motor Skills}
% Goal, Method (Strength), Verification + Image
In Chapter 7, I will show how to optimize parametrized motor skills that are
essential for autonomous robots operating in an unpredictable environment. 
By evolving a parametrized probability distribution, the algorithm reduces 
the number of samples required to optimize a parametrized skill for 
all the tasks in the range of interest. 

\section{Model-based Learning for virtual and real characters}
% Introduction on the bias

\section{Contributions}
The control and optimization methods discussed in this dissertation provide
several contributions to the computer animation community. 
These contributions are as follows:


\begin{itemize}
\item \textbf{A falling and landing strategy for various initial conditions}
  The algorithm presented in the dissertation allows the character to fall from 
  a wide range of heights and initial speeds, continuously roll on the ground, 
  and get back on its feet, without inducing large stress on joints at any
  moment.
\item \textbf{A multiple contact falling strategy for humanoids}
  We introduce a new planning algorithm to minimize the damage of humanoid 
  falls by utilizing multiple contact points. 
\item \textbf{An iterative learning framework for dynamic motor skills}
  Inspired by how humans learn dynamic motor skills through progressive process 
  of coaching and practices, we introduce an intuitive and interactive 
  framework for developing dynamic controllers. 
\item \textbf{An optimization technique that utilized failed samples}
  We introduce a novel efficient optimization algorithm, CMA-C, that shows 
  that faster convergence rate by approximating the infeasible region of a  
  particular type of failure with Supported Vector Machines.
\item \textbf{An optimization technique for parametrized objectives}
  We introduces an efficient evolutionary optimization algorithm for learning
  parametrized skills to achieve whole-body dynamic tasks. 
\end{itemize}

